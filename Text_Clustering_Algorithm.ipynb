{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#TEXT CLUSTERING\n"
      ],
      "metadata": {
        "id": "VFMfxwGW5TDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import re"
      ],
      "metadata": {
        "id": "8dR3batE31l6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "'''\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer vmMtGjKoFFc65vjv2cKDNj70vHbOeUJcN6GgWPJ5eeA\"\n",
        "}\n",
        "'''\n",
        "\n",
        "\n",
        "response = requests.get(f\"https://mastodon.social/api/v1/timelines/public?limit=40\")\n",
        "\n",
        "# Get the JSON data from the response\n",
        "data = response.json()\n",
        "\n"
      ],
      "metadata": {
        "id": "-B52kpfZjKxq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data_frame =json.loads(response.text)\n",
        "#data_frame"
      ],
      "metadata": {
        "id": "ROTiVlFHkx-N"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CLEANING THE DATA"
      ],
      "metadata": {
        "id": "Eg_w99H9R3LT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import csv\n",
        "import re\n",
        "from html import unescape\n",
        "\n",
        "def clean_content(content):\n",
        "    # Remove HTML tags\n",
        "    clean = re.sub(r'<[^>]+>', '', content)\n",
        "    # Unescape HTML entities\n",
        "    clean = unescape(clean)\n",
        "    # Remove URLs\n",
        "    clean = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', clean)\n",
        "    # Remove emojis and special characters\n",
        "    clean = re.sub(r'[^\\w\\s.,!?]', '', clean)\n",
        "    # Remove extra whitespace\n",
        "    clean = ' '.join(clean.split())\n",
        "    # Remove timestamps, dates, and other non-essential information\n",
        "    clean = re.sub(r'\\d{1,2}:\\d{2}(-\\d{1,2}:\\d{2})?(\\s+UTC)?', '', clean)\n",
        "    clean = re.sub(r'\\b(Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday)\\b', '', clean)\n",
        "    clean = re.sub(r'\\d{1,2}(st|nd|rd|th)', '', clean)\n",
        "    # Remove any remaining parentheses and their contents\n",
        "    clean = re.sub(r'\\([^)]*\\)', '', clean)\n",
        "    # Final cleanup of extra spaces\n",
        "    clean = ' '.join(clean.split())\n",
        "    return clean.strip()\n",
        "\n",
        "# Load the JSON data\n",
        "data = json.loads(response.text)\n",
        "\n",
        "# Prepare data for CSV\n",
        "csv_data = []\n",
        "for item in data:\n",
        "    if item.get('language') == 'en':\n",
        "        cleaned_content = clean_content(item['content'])\n",
        "        # Only include non-empty content\n",
        "        if cleaned_content:\n",
        "            csv_data.append({\n",
        "                'id': item['id'],\n",
        "                'language': item['language'],\n",
        "                'content': cleaned_content\n",
        "            })\n",
        "\n",
        "# Write to CSV\n",
        "with open('cleaned_output.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "    fieldnames = ['id', 'language', 'content']\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "    writer.writeheader()\n",
        "    for row in csv_data:\n",
        "        writer.writerow(row)\n",
        "\n",
        "print(\"CSV file 'cleaned_output.csv' has been created successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJURTWOGEara",
        "outputId": "276d194f-f0ae-4c94-e590-2bae9df065ae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file 'cleaned_output.csv' has been created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('cleaned_output.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WFWjJzDYEmNi",
        "outputId": "ba03d73d-f37d-48ec-8bd3-354ba8c32c84"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    id language  \\\n",
              "0   113171522990868526       en   \n",
              "1   113171522923192658       en   \n",
              "2   113171522889258215       en   \n",
              "3   113171522879043094       en   \n",
              "4   113171522871114137       en   \n",
              "5   113171522849668217       en   \n",
              "6   113171522844025296       en   \n",
              "7   113171522807752059       en   \n",
              "8   113171522764678508       en   \n",
              "9   113171522734576065       en   \n",
              "10  113171522720019219       en   \n",
              "11  113171522719971719       en   \n",
              "12  113171522718919872       en   \n",
              "13  113171522685752402       en   \n",
              "14  113171522685642750       en   \n",
              "15  113171522616928111       en   \n",
              "16  113171522615176852       en   \n",
              "17  113171522586246878       en   \n",
              "18  113171522573252460       en   \n",
              "19  113171522564870556       en   \n",
              "20  113171522503269209       en   \n",
              "21  113171522502334520       en   \n",
              "22  113171522488127893       en   \n",
              "23  113171522482245998       en   \n",
              "24  113171522471331214       en   \n",
              "25  113171522439400460       en   \n",
              "26  113171522436908450       en   \n",
              "27  113171522429443829       en   \n",
              "28  113171522364969668       en   \n",
              "29  113171522353369710       en   \n",
              "30  113171522337270217       en   \n",
              "\n",
              "                                              content  \n",
              "0   Google employees attempts to hide messages fro...  \n",
              "1   New APK Google Drive 2.24.367.5.all by Google LLC  \n",
              "2   for all the motorcycle folk on here, how would...  \n",
              "3   New APK Google Drive 2.24.377.4.all by Google LLC  \n",
              "4   Virat Kohlis Test average falls to eightyear l...  \n",
              "5         Φωτιά ΧΥΤΑ_Καρπάθου Φωτιά στο ΧΥΤΑ Καρπάθου  \n",
              "6   Hezbollahs Big Rocket Attack Minutes After IDF...  \n",
              "7   I eveny him, wish I could be him Ashwin hails ...  \n",
              "8   Imran Khans party gets permit for rally after ...  \n",
              "9   Halle Berry surprises fans at special wig scre...  \n",
              "10  I long found it interesting that my Yaesu FTdx...  \n",
              "11                   Nu op KINK Creeps Ooh! I Like It  \n",
              "12  Public health projects worth 9.18 crore launch...  \n",
              "13  Wahahaha, the irony of openai wanting me to so...  \n",
              "14  These evangelicals are voting their values by ...  \n",
              "15  Britain Covey backs up trust of Jalen Hurts, E...  \n",
              "16                                           Goa Head  \n",
              "17  Best CFB matchups to watch during Georgias bye...  \n",
              "18     Dameon Pierce hamstring listed out for Week 3.  \n",
              "19        Joe Mixon ankle listed doubtful for Week 3.  \n",
              "20  Justin Herbert injury update Chargers QB says ...  \n",
              "21  Now, is this racist?Sounds a bit Farage for me...  \n",
              "22  Now playing on the radiofreefedi.net word chan...  \n",
              "23  BREAKING Texas NeoNazi Arrested and Charged wi...  \n",
              "24  holyshit fixing firefox was this easy?? well i...  \n",
              "25                             totp I dont like ganja  \n",
              "26  totp good tune. Is it considered cultural appr...  \n",
              "27  I wasnt made for capitalism I was made to be f...  \n",
              "28  that we could not be silenced but rather that,...  \n",
              "29  Hearing Dylan Guenther and Utah closing in on ...  \n",
              "30  PlaneAlert ICAO AE093D Tail 0100301 Owner Unit...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3573b410-c12e-42a1-a77c-0eea612b5ade\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>language</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>113171522990868526</td>\n",
              "      <td>en</td>\n",
              "      <td>Google employees attempts to hide messages fro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>113171522923192658</td>\n",
              "      <td>en</td>\n",
              "      <td>New APK Google Drive 2.24.367.5.all by Google LLC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>113171522889258215</td>\n",
              "      <td>en</td>\n",
              "      <td>for all the motorcycle folk on here, how would...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>113171522879043094</td>\n",
              "      <td>en</td>\n",
              "      <td>New APK Google Drive 2.24.377.4.all by Google LLC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>113171522871114137</td>\n",
              "      <td>en</td>\n",
              "      <td>Virat Kohlis Test average falls to eightyear l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>113171522849668217</td>\n",
              "      <td>en</td>\n",
              "      <td>Φωτιά ΧΥΤΑ_Καρπάθου Φωτιά στο ΧΥΤΑ Καρπάθου</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>113171522844025296</td>\n",
              "      <td>en</td>\n",
              "      <td>Hezbollahs Big Rocket Attack Minutes After IDF...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>113171522807752059</td>\n",
              "      <td>en</td>\n",
              "      <td>I eveny him, wish I could be him Ashwin hails ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>113171522764678508</td>\n",
              "      <td>en</td>\n",
              "      <td>Imran Khans party gets permit for rally after ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>113171522734576065</td>\n",
              "      <td>en</td>\n",
              "      <td>Halle Berry surprises fans at special wig scre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>113171522720019219</td>\n",
              "      <td>en</td>\n",
              "      <td>I long found it interesting that my Yaesu FTdx...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>113171522719971719</td>\n",
              "      <td>en</td>\n",
              "      <td>Nu op KINK Creeps Ooh! I Like It</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>113171522718919872</td>\n",
              "      <td>en</td>\n",
              "      <td>Public health projects worth 9.18 crore launch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>113171522685752402</td>\n",
              "      <td>en</td>\n",
              "      <td>Wahahaha, the irony of openai wanting me to so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>113171522685642750</td>\n",
              "      <td>en</td>\n",
              "      <td>These evangelicals are voting their values by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>113171522616928111</td>\n",
              "      <td>en</td>\n",
              "      <td>Britain Covey backs up trust of Jalen Hurts, E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>113171522615176852</td>\n",
              "      <td>en</td>\n",
              "      <td>Goa Head</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>113171522586246878</td>\n",
              "      <td>en</td>\n",
              "      <td>Best CFB matchups to watch during Georgias bye...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>113171522573252460</td>\n",
              "      <td>en</td>\n",
              "      <td>Dameon Pierce hamstring listed out for Week 3.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>113171522564870556</td>\n",
              "      <td>en</td>\n",
              "      <td>Joe Mixon ankle listed doubtful for Week 3.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>113171522503269209</td>\n",
              "      <td>en</td>\n",
              "      <td>Justin Herbert injury update Chargers QB says ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>113171522502334520</td>\n",
              "      <td>en</td>\n",
              "      <td>Now, is this racist?Sounds a bit Farage for me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>113171522488127893</td>\n",
              "      <td>en</td>\n",
              "      <td>Now playing on the radiofreefedi.net word chan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>113171522482245998</td>\n",
              "      <td>en</td>\n",
              "      <td>BREAKING Texas NeoNazi Arrested and Charged wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>113171522471331214</td>\n",
              "      <td>en</td>\n",
              "      <td>holyshit fixing firefox was this easy?? well i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>113171522439400460</td>\n",
              "      <td>en</td>\n",
              "      <td>totp I dont like ganja</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>113171522436908450</td>\n",
              "      <td>en</td>\n",
              "      <td>totp good tune. Is it considered cultural appr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>113171522429443829</td>\n",
              "      <td>en</td>\n",
              "      <td>I wasnt made for capitalism I was made to be f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>113171522364969668</td>\n",
              "      <td>en</td>\n",
              "      <td>that we could not be silenced but rather that,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>113171522353369710</td>\n",
              "      <td>en</td>\n",
              "      <td>Hearing Dylan Guenther and Utah closing in on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>113171522337270217</td>\n",
              "      <td>en</td>\n",
              "      <td>PlaneAlert ICAO AE093D Tail 0100301 Owner Unit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3573b410-c12e-42a1-a77c-0eea612b5ade')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3573b410-c12e-42a1-a77c-0eea612b5ade button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3573b410-c12e-42a1-a77c-0eea612b5ade');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-26df1144-bb17-4182-ba9c-01aaf448c947\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-26df1144-bb17-4182-ba9c-01aaf448c947')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-26df1144-bb17-4182-ba9c-01aaf448c947 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d6894ac7-4bd4-4916-9bfe-f2b629a262be\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d6894ac7-4bd4-4916-9bfe-f2b629a262be button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 31,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 186266736,\n        \"min\": 113171522337270217,\n        \"max\": 113171522990868526,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          113171522429443829,\n          113171522616928111,\n          113171522482245998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"language\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"en\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31,\n        \"samples\": [\n          \"I wasnt made for capitalism I was made to be frozen in ash during the explosion of Pompeii.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers scikit-learn torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxPLcYemHsqG",
        "outputId": "2db665bb-da57-4e43-f9c6-43a2b2ed867e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ikm_y80RLy9H",
        "outputId": "e8cf00be-1f07-43e4-d977-1a28bd2af13e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.8.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m107.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.8.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1ST APPORACH USING TEXT CLUSTERING ALGORITHM(Hierarchical clustering)"
      ],
      "metadata": {
        "id": "3BpNYnfhRB_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "from sklearn.metrics import silhouette_score\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Use BERT to convert each sentence into a vector\n",
        "class BERTEmbedding:\n",
        "    def __init__(self):\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    def encode(self, sentence):\n",
        "        # Tokenize and encode sentence\n",
        "        inputs = self.tokenizer(sentence, return_tensors='pt', padding=True, truncation=True)\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "\n",
        "        # Get the sentence embedding (average of the last hidden states)\n",
        "        sentence_embedding = torch.mean(outputs.last_hidden_state, dim=1)\n",
        "        return sentence_embedding.squeeze().numpy()\n",
        "\n",
        "# Step 2: Use SpaCy to recognize Named Entities (NER) and filter meaningful keywords\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_named_entities_and_keywords(sentence):\n",
        "    doc = nlp(sentence)\n",
        "\n",
        "    # Extract named entities (like persons, organizations)\n",
        "    entities = [ent.text for ent in doc.ents if ent.label_ in ('PERSON', 'ORG', 'GPE')]\n",
        "\n",
        "    # Combine multi-word entities into single entities\n",
        "    combined_entities = combine_multi_word_entities(entities)\n",
        "\n",
        "    # Extract non-adjective keywords (ignoring \"good\", \"very\", etc.), filtering out entities\n",
        "    keywords = [token.text for token in doc if token.pos_ in ('NOUN', 'PROPN') and token.text not in combined_entities]\n",
        "\n",
        "    return combined_entities, keywords\n",
        "\n",
        "# Function to combine multi-word entities (e.g., \"Banotu Ganesh\")\n",
        "def combine_multi_word_entities(entities):\n",
        "    multi_word_entities = []\n",
        "    for entity in entities:\n",
        "        if ' ' in entity:\n",
        "            multi_word_entities.append(entity)\n",
        "        else:\n",
        "            if not any(entity in e for e in multi_word_entities):\n",
        "                multi_word_entities.append(entity)\n",
        "    return list(set(multi_word_entities))\n",
        "\n",
        "# Step 3: Apply Hierarchical Clustering to group similar sentences into clusters\n",
        "def cluster_sentences(sentences, n_clusters=None):\n",
        "    bert_embedding = BERTEmbedding()\n",
        "    embeddings = np.array([bert_embedding.encode(sentence) for sentence in sentences])\n",
        "\n",
        "    # Compute pairwise cosine distances\n",
        "    distances = cosine_distances(embeddings)\n",
        "\n",
        "    # Apply Agglomerative Clustering\n",
        "    clustering = AgglomerativeClustering(n_clusters=n_clusters, affinity='precomputed', linkage='complete')\n",
        "    labels = clustering.fit_predict(distances)\n",
        "\n",
        "    return clustering, labels\n",
        "\n",
        "# Step 4: Extract key terms for each cluster\n",
        "def extract_cluster_keywords(sentences, labels):\n",
        "    cluster_keywords = {}\n",
        "    unique_labels = set(labels)\n",
        "\n",
        "    for label in unique_labels:\n",
        "        cluster_sentences = [sentences[i] for i in range(len(sentences)) if labels[i] == label]\n",
        "        cluster_entities_keywords = []\n",
        "\n",
        "        for sentence in cluster_sentences:\n",
        "            entities, keywords = extract_named_entities_and_keywords(sentence)\n",
        "            cluster_entities_keywords.extend(entities + keywords)\n",
        "\n",
        "        # Deduplicate and store the entities/keywords for the cluster\n",
        "        cluster_keywords[label] = list(set(cluster_entities_keywords))\n",
        "\n",
        "    return cluster_keywords\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Sample list of sentences to cluster (replace this with your actual data)\n",
        "    sentences = [\n",
        "        \"Halle Berry surprises fans at special wig screening of her upcoming movie.\",\n",
        "        \"The movie Never Let Go is released today.\",\n",
        "        \"Berry donned her iconic hairstyle from her 2013 film, The Call.\",\n",
        "        \"New technology is changing the way we interact with films.\",\n",
        "        # Add more sentences as needed...\n",
        "    ]\n",
        "\n",
        "    # Step 1: Determine the best number of clusters using silhouette score\n",
        "    best_n_clusters = 0\n",
        "    best_score = -1\n",
        "    bert_embedding = BERTEmbedding()  # Initialize BERTEmbedding once for use\n",
        "\n",
        "    for n in range(2, len(sentences)):  # Testing different cluster sizes\n",
        "        # only test for number of clusters less than the number of sentences\n",
        "        clustering, labels = cluster_sentences(sentences, n)\n",
        "        score = silhouette_score(cosine_distances(np.array([bert_embedding.encode(s) for s in sentences])), labels)\n",
        "\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_n_clusters = n\n",
        "\n",
        "    print(f\"Best number of clusters: {best_n_clusters} with silhouette score: {best_score}\")\n",
        "\n",
        "    # Step 2: Cluster sentences using the best number of clusters\n",
        "    clustering, labels = cluster_sentences(sentences, best_n_clusters)\n",
        "\n",
        "    # Step 3: Extract key terms for each cluster\n",
        "    cluster_keywords = extract_cluster_keywords(sentences, labels)\n",
        "    print(f\"Cluster Keywords: {cluster_keywords}\")\n",
        "\n",
        "    # Step 4: Predict the category for a new sentence based on cluster membership\n",
        "    new_sentence = \"Halle Berry surprises fans at special wig screening of her upcoming movie Never Let Go.\"\n",
        "    entities, keywords = extract_named_entities_and_keywords(new_sentence)\n",
        "\n",
        "    # Combine entities and keywords, remove duplicates\n",
        "    categories = list(set(entities + keywords))\n",
        "\n",
        "    print(f\"Sentence: {new_sentence}\")\n",
        "    print(f\"Groups belong to: {', '.join(categories)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNVjjU5cQ3ct",
        "outputId": "6ed80d90-a7c4-43ce-8b75-474a7e348707"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_agglomerative.py:1006: FutureWarning: Attribute `affinity` was deprecated in version 1.2 and will be removed in 1.4. Use `metric` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_agglomerative.py:1006: FutureWarning: Attribute `affinity` was deprecated in version 1.2 and will be removed in 1.4. Use `metric` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best number of clusters: 2 with silhouette score: 0.1789727807044983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Keywords: {0: ['technology', 'today', 'way', 'movie', 'films'], 1: ['Halle Berry', 'film', 'wig', 'fans', 'Halle', 'Call', 'Berry', 'movie', 'hairstyle', 'screening']}\n",
            "Sentence: Halle Berry surprises fans at special wig screening of her upcoming movie Never Let Go.\n",
            "Groups belong to: Halle Berry, wig, fans, Halle, Berry, movie, screening\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_agglomerative.py:1006: FutureWarning: Attribute `affinity` was deprecated in version 1.2 and will be removed in 1.4. Use `metric` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SECOND APPORACH USING BertModel AND spacy"
      ],
      "metadata": {
        "id": "Ux3pyRwRReqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SECOND CODE\n",
        "import spacy\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Use BERT to convert each sentence into a vector\n",
        "class BERTEmbedding:\n",
        "    def __init__(self):\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    def encode(self, sentence):\n",
        "        # Tokenize and encode sentence\n",
        "        inputs = self.tokenizer(sentence, return_tensors='pt', padding=True, truncation=True)\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "\n",
        "        # Get the sentence embedding (average of the last hidden states)\n",
        "        sentence_embedding = torch.mean(outputs.last_hidden_state, dim=1)\n",
        "        return sentence_embedding.squeeze().numpy()\n",
        "\n",
        "# Step 2: Use SpaCy to recognize Named Entities (NER) and filter meaningful keywords\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_named_entities_and_keywords(sentence):\n",
        "    doc = nlp(sentence)\n",
        "\n",
        "    # Extract named entities (like persons, organizations, places)\n",
        "    entities = [ent.text for ent in doc.ents if ent.label_ in ('PERSON', 'ORG', 'GPE')]\n",
        "\n",
        "    # Combine multi-word entities into single entities\n",
        "    combined_entities = combine_multi_word_entities(entities)\n",
        "\n",
        "    # Extract meaningful keywords (nouns) and filter out entities\n",
        "    keywords = [token.text for token in doc if token.pos_ == 'NOUN' and token.text not in combined_entities]\n",
        "\n",
        "    return combined_entities, keywords\n",
        "\n",
        "# Function to combine multi-word entities (e.g., \"Banotu Ganesh\", \"Rahul Dindigal\")\n",
        "def combine_multi_word_entities(entities):\n",
        "    multi_word_entities = []\n",
        "    for entity in entities:\n",
        "        # Keep the entity intact if it's multi-word\n",
        "        if ' ' in entity:\n",
        "            multi_word_entities.append(entity)\n",
        "        else:\n",
        "            # Avoid partial matches for single-word entities\n",
        "            if not any(entity in e for e in multi_word_entities):\n",
        "                multi_word_entities.append(entity)\n",
        "    return list(set(multi_word_entities))\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    for i in df['content']:\n",
        "      new_sentence_2 = i\n",
        "    # Use NER to extract proper entities and keywords from the sentence\n",
        "      entities_2, keywords_2 = extract_named_entities_and_keywords(new_sentence_2)\n",
        "\n",
        "    # Combine entities and keywords, ensuring no duplicates\n",
        "      categories_2 = list(set(entities_2 + keywords_2))\n",
        "\n",
        "    # Output the final groups, formatted as expected\n",
        "      print(f\"\\nSentence: {new_sentence_2}\")\n",
        "      print(f\"Groups belong to: {', '.join(categories_2)}\\n\")\n"
      ],
      "metadata": {
        "id": "cosU-xJTOm01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6161e84b-9710-42cb-f411-36639e535556"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence: Google employees attempts to hide messages from investigators might backfire Posted into Features from The Verge featuresfromthevergetheverge\n",
            "Groups belong to: employees, investigators, featuresfromthevergetheverge, Google, Features, messages\n",
            "\n",
            "\n",
            "Sentence: New APK Google Drive 2.24.367.5.all by Google LLC\n",
            "Groups belong to: Google\n",
            "\n",
            "\n",
            "Sentence: for all the motorcycle folk on here, how would you have taken this strange little railway bridge on a backroad?motorcyclesmotorrad\n",
            "Groups belong to: railway, folk, backroad?motorcyclesmotorrad, motorcycle, bridge\n",
            "\n",
            "\n",
            "Sentence: New APK Google Drive 2.24.377.4.all by Google LLC\n",
            "Groups belong to: Google\n",
            "\n",
            "\n",
            "Sentence: Virat Kohlis Test average falls to eightyear low In both innings of the Test, Kohli delivered poor scores of 6 and 17. While in the first innings, he chased an outside off stump delivery by Hasan Mahmud, in the second innings, he fell victim to a wrong legbeforewicket decision. Having chosen to not review it, the Ultraedge discovered the bat making... press\n",
            "Groups belong to: Ultraedge, scores, outside, press, stump, decision, victim, bat, innings, average, legbeforewicket, delivery, Hasan Mahmud, Virat Kohlis Test\n",
            "\n",
            "\n",
            "Sentence: Φωτιά ΧΥΤΑ_Καρπάθου Φωτιά στο ΧΥΤΑ Καρπάθου\n",
            "Groups belong to: Φωτιά, στο\n",
            "\n",
            "\n",
            "Sentence: Hezbollahs Big Rocket Attack Minutes After IDFs Beirut Strike Israeli Air Defences Fail LebanonSoon after IDFs strike in Lebanon Beirut, Hezbollah fired a volley of rockets at Northern Israel. Times of Israel reported a barrage of some 20 rockets was launched from Lebanon. Hezbollahs rocket... press\n",
            "Groups belong to: rockets, barrage, rocket, press, strike, Beirut Strike, Air Defences Fail LebanonSoon, Hezbollah, Israel, Times, volley\n",
            "\n",
            "\n",
            "Sentence: I eveny him, wish I could be him Ashwin hails Jadeja for his remarkable display against Bangladesh Indias veteran spinner Ravichandran Ashwin showered praise on his teammate Ravindra Jadeja and said that he always envies him. press\n",
            "Groups belong to: display, press, spinner, Ashwin, teammate, Ravindra Jadeja, Ravichandran Ashwin, Jadeja, Bangladesh Indias, praise, veteran\n",
            "\n",
            "\n",
            "Sentence: Imran Khans party gets permit for rally after PTI announced to hold power show even as Pak govt. pulls all stops to prevent itImran Khans party gets permit for rally after PTI announced to hold power show even as Pak govt. pulls all stops to prevent it press\n",
            "Groups belong to: party, show, Imran Khans party, rally, PTI, permit, power, stops, govt\n",
            "\n",
            "\n",
            "Sentence: Halle Berry surprises fans at special wig screening of her upcoming movie Never Let Go out todayBerry donned her iconic hairstyle from her 2013 film, The Call.\n",
            "Groups belong to: Halle Berry, film, wig, fans, movie, hairstyle, screening\n",
            "\n",
            "\n",
            "Sentence: I long found it interesting that my Yaesu FTdx3000 made a relay click when moving the AF knob out of or into its CCW stop. I wondered why.Now I know my FT991A makes no such click, with the AF Gain turned fully CCW, a strong FT8 signal can still be faintly heard if the rest of the room is quiet.The 3000 must use a relay to disconnect the speakerphones completely.HamRadio\n",
            "Groups belong to: rest, Yaesu, click, CCW, HamRadio, stop, FT8, room, knob, speakerphones, relay, signal\n",
            "\n",
            "\n",
            "Sentence: Nu op KINK Creeps Ooh! I Like It\n",
            "Groups belong to: KINK Creeps Ooh, op\n",
            "\n",
            "\n",
            "Sentence: Public health projects worth 9.18 crore launched in Ernakulam15 programmes inaugurated in Aluva, Piravom, Vypeen, Paravur, Perumbavoor and Kunnathunad Assembly constituencies Cochin Cancer Centre to become functional in a few months, says Health Minister press\n",
            "Groups belong to: Cochin Cancer Centre, press, Perumbavoor, programmes, months, constituencies, Health, Aluva, crore, Kunnathunad Assembly, Piravom, health, projects\n",
            "\n",
            "\n",
            "Sentence: Wahahaha, the irony of openai wanting me to solve a puzzle to prove that Im human before I can sign in\n",
            "Groups belong to: openai, puzzle, irony\n",
            "\n",
            "\n",
            "Sentence: These evangelicals are voting their values by backing Kamala HarrisThese evangelicals are voting their values by backing Kamala Harris press\n",
            "Groups belong to: press, values, Kamala HarrisThese, evangelicals, Kamala Harris\n",
            "\n",
            "\n",
            "Sentence: Britain Covey backs up trust of Jalen Hurts, Eagles coaches with career performance He showed up for us\n",
            "Groups belong to: career, performance, Eagles, Jalen Hurts, trust, Britain Covey\n",
            "\n",
            "\n",
            "Sentence: Goa Head\n",
            "Groups belong to: \n",
            "\n",
            "\n",
            "Sentence: Best CFB matchups to watch during Georgias bye week\n",
            "Groups belong to: week, matchups\n",
            "\n",
            "\n",
            "Sentence: Dameon Pierce hamstring listed out for Week 3.\n",
            "Groups belong to: hamstring, Dameon Pierce\n",
            "\n",
            "\n",
            "Sentence: Joe Mixon ankle listed doubtful for Week 3.\n",
            "Groups belong to: ankle, Joe Mixon\n",
            "\n",
            "\n",
            "Sentence: Justin Herbert injury update Chargers QB says hes dealing with high ankle sprain, questionable vs. Steelers\n",
            "Groups belong to: update, Chargers QB, Steelers, ankle, injury, Justin Herbert, sprain\n",
            "\n",
            "\n",
            "Sentence: Now, is this racist?Sounds a bit Farage for metotp\n",
            "Groups belong to: Farage, bit\n",
            "\n",
            "\n",
            "Sentence: Now playing on the radiofreefedi.net word channelSenses by Shaine Greenwood in now with radiofreefediyour 247 community radio from the fediverse to the universerffPlays rffWord\n",
            "Groups belong to: word, channelSenses, radio, fediverse, Shaine Greenwood, rffWord, universerffPlays, community\n",
            "\n",
            "\n",
            "Sentence: BREAKING Texas NeoNazi Arrested and Charged with Making Threats to Kill Nashville District Attorney Glenn Funk 1\n",
            "Groups belong to: BREAKING Texas NeoNazi, Glenn Funk, Threats\n",
            "\n",
            "\n",
            "Sentence: holyshit fixing firefox was this easy?? well ive finally got HD video back, no more 140pp for me!!yikes xD\n",
            "Groups belong to: holyshit, video, 140pp, firefox\n",
            "\n",
            "\n",
            "Sentence: totp I dont like ganja\n",
            "Groups belong to: ganja\n",
            "\n",
            "\n",
            "Sentence: totp good tune. Is it considered cultural appropriation nowadays though?\n",
            "Groups belong to: appropriation, tune\n",
            "\n",
            "\n",
            "Sentence: I wasnt made for capitalism I was made to be frozen in ash during the explosion of Pompeii.\n",
            "Groups belong to: Pompeii, explosion, capitalism, ash\n",
            "\n",
            "\n",
            "Sentence: that we could not be silenced but rather that, if we are forced by the violence of legislation to be silent, we will nevertheless continue to be who we are. We will continue to live however we please under any deplorable condition that is inflicted upon us.Despite the attempts from some despicable people to erase us, we will certainly not be erased. Our sexual orientations and felt senses of who we are are at least in part produced by the human genome and epigenome. We are of course a...7n\n",
            "Groups belong to: attempts, part, orientations, epigenome, people, course, condition, genome, senses, 7n, legislation, violence\n",
            "\n",
            "\n",
            "Sentence: Hearing Dylan Guenther and Utah closing in on an eightyear extension at slightly above 7M per. The Utahns lock up a key piece.\n",
            "Groups belong to: per, piece, Utah, Utahns, extension, Dylan Guenther, eightyear\n",
            "\n",
            "\n",
            "Sentence: PlaneAlert ICAO AE093D Tail 0100301 Owner UnitedStatesArmyAircraft Cessna UC35B Citation20240920 152600C560 VIPTransport Bizjet MustBeNice planefence adsb dockerkx1tplanefence\n",
            "Groups belong to: dockerkx1tplanefence, VIPTransport, Tail 0100301, PlaneAlert ICAO, adsb, UC35B, Cessna, planefence, MustBeNice\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3o7n3DCixW8M"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sdTr9SpD0x50"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "170YAoPW1OEJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eza1C4LMA7Fj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VK3VHIx6A6_K"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k7sI2XBaA636"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmkpLvVHA6vW",
        "outputId": "f9a5d327-f97e-44f5-a0f2-e59018dd5327"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YH9HyX5I4wbg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0c06728-4f8d-45b1-cbc4-199c136381d9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lqlZGJnLTJP0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}